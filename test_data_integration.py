"""
ãƒ‡ãƒ¼ã‚¿çµ±åˆã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãçµ±åˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
"""

import pandas as pd
import json
from pathlib import Path
import requests
import time

PROJECT_ROOT = Path(__file__).parent
DATA_PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"
API_BASE_URL = "http://localhost:5001/api"


def test_data_files():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã¨å†…å®¹ã‚’ç¢ºèª"""
    print("=" * 60)
    print("Testing Data Files")
    print("=" * 60)
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª
    combined_path = DATA_PROCESSED_DIR / "combined_dataset.csv"
    if not combined_path.exists():
        print("âŒ ERROR: combined_dataset.csv not found")
        return False
    
    df = pd.read_csv(combined_path)
    print(f"âœ… Combined dataset found: {len(df)} data points")
    print(f"   Year range: {df['year'].min()}-{df['year'].max()}")
    print(f"   Columns: {', '.join(df.columns)}")
    
    # ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
    print("\nData completeness:")
    print(f"   Labor hours: {df['hours_per_year'].notna().sum()}/{len(df)} ({df['hours_per_year'].notna().sum()/len(df)*100:.1f}%)")
    print(f"   GDP growth: {df['gdp_growth_rate'].notna().sum()}/{len(df)} ({df['gdp_growth_rate'].notna().sum()/len(df)*100:.1f}%)")
    print(f"   GDP per capita: {df['gdp_per_capita_usd'].notna().sum()}/{len(df)} ({df['gdp_per_capita_usd'].notna().sum()/len(df)*100:.1f}%)")
    print(f"   Reading time: {df['reading_minutes_per_day'].notna().sum()}/{len(df)} ({df['reading_minutes_per_day'].notna().sum()/len(df)*100:.1f}%)")
    
    # ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    print("\nData validity checks:")
    
    # åŠ´åƒæ™‚é–“ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ1000-3000æ™‚é–“ã®ç¯„å›²å†…ï¼‰
    valid_hours = df['hours_per_year'].between(1000, 3000).sum()
    print(f"   Labor hours in valid range (1000-3000): {valid_hours}/{df['hours_per_year'].notna().sum()}")
    
    # GDPæˆé•·ç‡ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆ-10%ã‹ã‚‰15%ã®ç¯„å›²å†…ï¼‰
    valid_gdp_growth = df['gdp_growth_rate'].between(-10, 15).sum()
    print(f"   GDP growth in valid range (-10% to 15%): {valid_gdp_growth}/{df['gdp_growth_rate'].notna().sum()}")
    
    # ç›¸é–¢åˆ†æçµæœã®ç¢ºèª
    correlation_path = DATA_PROCESSED_DIR / "correlation_analysis.json"
    if correlation_path.exists():
        with open(correlation_path, 'r', encoding='utf-8') as f:
            correlation = json.load(f)
        print(f"\nâœ… Correlation analysis found: {len(correlation)} indicators")
        for indicator, result in correlation.items():
            if result:
                print(f"   {indicator}: r={result['pearson_correlation']:.4f}, p={result['pearson_p_value']:.4f}")
    
    return True


def test_api_endpoints():
    """APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("Testing API Endpoints")
    print("=" * 60)
    
    # ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
    try:
        response = requests.get(f"{API_BASE_URL}/../health", timeout=5)
        if response.status_code != 200:
            print("âš ï¸  WARNING: Backend server may not be running")
            print("   Please start the server with: python run_server.py")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ ERROR: Cannot connect to backend server")
        print("   Please start the server with: python run_server.py")
        return False
    
    # å¹´ç¯„å›²ã®å–å¾—
    try:
        response = requests.get(f"{API_BASE_URL}/year-range", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Year range API: {data['min']}-{data['max']}")
        else:
            print(f"âŒ ERROR: Year range API returned status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ERROR: Year range API test failed: {e}")
        return False
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãƒ†ã‚¹ãƒˆ
    try:
        response = requests.get(f"{API_BASE_URL}/data?start_year=2020&end_year=2023", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Data API: Retrieved {data['count']} records (2020-2023)")
            
            # ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ç¢ºèª
            if data['count'] > 0:
                sample = data['data'][0]
                print(f"   Sample record: year={sample.get('year')}, hours={sample.get('hours_per_year')}, gdp_growth={sample.get('gdp_growth_rate')}")
        else:
            print(f"âŒ ERROR: Data API returned status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ERROR: Data API test failed: {e}")
        return False
    
    # ç›¸é–¢åˆ†æã®ãƒ†ã‚¹ãƒˆ
    try:
        response = requests.get(f"{API_BASE_URL}/correlation?indicator=gdp_growth_rate", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Correlation API: r={data['pearson_correlation']:.4f}, p={data['pearson_p_value']:.4f}")
        else:
            print(f"âŒ ERROR: Correlation API returned status {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ERROR: Correlation API test failed: {e}")
        return False
    
    return True


def test_data_consistency():
    """ãƒ‡ãƒ¼ã‚¿ã®ä¸€è²«æ€§ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("Testing Data Consistency")
    print("=" * 60)
    
    df = pd.read_csv(DATA_PROCESSED_DIR / "combined_dataset.csv")
    
    # æ™‚ç³»åˆ—ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    years = sorted(df['year'].unique())
    print(f"âœ… Year sequence: {years[0]}-{years[-1]} ({len(years)} years)")
    
    # åŠ´åƒæ™‚é–“ã®å‚¾å‘ãƒã‚§ãƒƒã‚¯ï¼ˆæ¸›å°‘å‚¾å‘ã§ã‚ã‚‹ã¹ãï¼‰
    recent_hours = df[df['year'] >= 2010]['hours_per_year'].mean()
    old_hours = df[df['year'] < 1980]['hours_per_year'].mean()
    if recent_hours < old_hours:
        print(f"âœ… Labor hours trend: Decreasing ({old_hours:.0f} â†’ {recent_hours:.0f} hours/year)")
    else:
        print(f"âš ï¸  WARNING: Unexpected labor hours trend")
    
    # GDPæˆé•·ç‡ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    gdp_data = df[df['gdp_growth_rate'].notna()]
    if len(gdp_data) > 0:
        avg_growth = gdp_data['gdp_growth_rate'].mean()
        print(f"âœ… Average GDP growth rate: {avg_growth:.2f}%")
    
    return True


def main():
    """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("\n" + "=" * 60)
    print("DATA INTEGRATION TEST")
    print("=" * 60)
    
    results = []
    
    results.append(("Data Files", test_data_files()))
    results.append(("API Endpoints", test_api_endpoints()))
    results.append(("Data Consistency", test_data_consistency()))
    
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    
    for test_name, result in results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        print(f"{test_name}: {status}")
    
    all_passed = all(result for _, result in results)
    
    if all_passed:
        print("\nğŸ‰ All tests passed! Real data is successfully integrated.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the errors above.")
    
    return all_passed


if __name__ == "__main__":
    main()

